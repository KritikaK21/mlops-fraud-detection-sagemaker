# üß† MLOps Pipeline for Fraud Detection using Amazon SageMaker

An end-to-end, fully automated MLOps pipeline for detecting fraudulent insurance claims using Amazon SageMaker. The pipeline covers the complete ML lifecycle ‚Äî data preprocessing, model training, bias detection, explainability, conditional deployment, and model governance ‚Äî using managed AWS services.

> **Scenario:** As an AIML Engineer at MindSpace, the goal was to build a scalable fraud detection system for a financial services client that automatically flags fraudulent transactions in real-time.

---

## üöÄ Tech Stack

| Category | Tools |
|----------|-------|
| Cloud Platform | Amazon SageMaker, AWS Lambda, Amazon S3 |
| ML Framework | XGBoost (binary classification) |
| Pipeline | SageMaker Pipelines |
| Fairness & Explainability | SageMaker Clarify (SHAP values, bias detection) |
| Model Governance | SageMaker Model Registry |
| Deployment | AWS Lambda, SageMaker Real-Time Endpoint |
| Monitoring | CloudWatch |
| IAM & Security | AWS IAM Roles & Policies |
| Language | Python, Jupyter Notebook |

---

## üèóÔ∏è Pipeline Architecture

```
Raw Data (S3)
     ‚Üì
[Step 1] Data Processing (SKLearnProcessor)
     ‚Üì ‚Üí Train (80%) / Validation (10%) / Test (10%)
[Step 2] XGBoost Model Training
     ‚Üì
[Step 3] Model Evaluation (ROC-AUC score)
     ‚Üì
[Step 4] Condition Check ‚Üí IF AUC ‚â• 0.7 ‚Üí Continue | ELSE ‚Üí Stop
     ‚Üì
[Step 5] Bias Detection (SageMaker Clarify - Gender Bias)
     ‚Üì
[Step 6] Explainability Check (SHAP Values)
     ‚Üì
[Step 7] Model Registration (SageMaker Model Registry)
     ‚Üì
[Step 8] Real-Time Endpoint Deployment (via AWS Lambda)
```

---

## üîÑ Pipeline Steps (Detailed)

### 1Ô∏è‚É£ Data Processing
- Merged two datasets: `claims.csv` + `customers.csv` (joined on `policy_id`)
- Handled missing values, one-hot encoded categorical features
- Ordinal encoded: `police_report_available`, `policy_liability`, `customer_education`
- Split data: **80% train / 10% validation / 10% test**
- Uploaded processed splits to Amazon S3

### 2Ô∏è‚É£ Model Training
- Algorithm: **XGBoost** (binary:logistic)
- Evaluation metric: **ROC-AUC**
- Key hyperparameters:
  - `max_depth`: 5
  - `eta`: 0.5
  - `subsample`: 0.75
  - `colsample_bytree`: 0.75
  - `num_round`: 5
- Used cross-validation during training
- Instance: `ml.m4.xlarge`

### 3Ô∏è‚É£ Model Evaluation
- Evaluated on held-out **test set**
- Metric: **ROC-AUC score**
- Results saved to `evaluation.json` in S3

### 4Ô∏è‚É£ Conditional Deployment
- Pipeline automatically checks: **IF ROC-AUC ‚â• 0.7 ‚Üí Deploy**
- If below threshold ‚Üí pipeline stops, model not deployed
- Ensures only high-quality models reach production

### 5Ô∏è‚É£ Bias Detection (SageMaker Clarify)
- Checked for **gender bias** in predictions (`customer_gender_female`)
- Method: **DPPL** (Difference in Positive Proportions of Labels)
- Ensures fairness and ethical AI compliance

### 6Ô∏è‚É£ Explainability (SHAP Values)
- Used **SHAP** to explain individual predictions
- Generated global and local feature importance scores
- Helps stakeholders understand WHY the model made a decision

### 7Ô∏è‚É£ Model Registry
- Registered model with:
  - Bias metrics
  - Explainability metrics
  - Drift check baselines
- Enables version control and model governance

### 8Ô∏è‚É£ Real-Time Endpoint Deployment
- **AWS Lambda** function (`lambda_deployer.py`) handles:
  - Creating SageMaker model
  - Creating endpoint configuration
  - Deploying real-time inference endpoint
- Instance: `ml.m4.xlarge`
- Endpoint returns **fraud probability** for each transaction

---

## üìä Model Details

**Dataset:** Synthetic automobile insurance claims  
**Source:** AWS SageMaker Sample Files (`sagemaker-sample-files`)  
**Task:** Binary Classification ‚Üí `fraud = 1` (fraudulent) / `fraud = 0` (legitimate)

**Key Features:**
- Transaction/claim details
- Customer demographics
- Policy information
- Historical patterns

**Evaluation Metric:** ROC-AUC  
**Deployment Threshold:** AUC ‚â• 0.7 (automated conditional check)

> ‚ö†Ô∏è Fraud detection problems prioritize **Recall** over Accuracy ‚Äî missing a fraudulent claim (false negative) is more costly than a false alarm.

---

## üìÅ Repository Structure

```
mlops-fraud-detection-sagemaker/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ MLOps-Sagemaker-Pipeline.ipynb    # Main pipeline notebook
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py                   # Data preprocessing script
‚îÇ   ‚îú‚îÄ‚îÄ xgboost_train.py                   # XGBoost training script
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                        # Model evaluation script
‚îÇ   ‚îî‚îÄ‚îÄ lambda_deployer.py                 # Lambda deployment function
‚îÇ
‚îú‚îÄ‚îÄ images/                                # Screenshots & architecture diagrams
‚îÇ   ‚îú‚îÄ‚îÄ jupyterlab-space.png
‚îÇ   ‚îú‚îÄ‚îÄ iam-role-config.png
‚îÇ   ‚îî‚îÄ‚îÄ notebook-execution.png
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

## üì∏ Project Setup Screenshots

### 1Ô∏è‚É£ JupyterLab Space Creation
Created a dedicated SageMaker JupyterLab space named `MLOps-pipeline` to run the pipeline.

![Jupyter Space Creation](images/01_create_jupyter_space_mlops_pipeline.png)

### 2Ô∏è‚É£ IAM Role Configuration
Attached required policies to `AmazonSageMaker-ExecutionRole`:
- `AmazonS3FullAccess`
- `AWSLambda_FullAccess`
- `CloudWatchFullAccess`

Updated trust policy to allow both `sagemaker.amazonaws.com` and `lambda.amazonaws.com`.

![IAM Policies Attached](images/02_iam_policies_attached_success.png)

### 3Ô∏è‚É£ Notebook Execution in SageMaker Studio
Pipeline notebook running inside SageMaker Studio with all imports loaded.

![Notebook Execution](images/03_sagemaker_jupyter_notebook_run.png)

---

## ‚öôÔ∏è How to Run This Project

### Prerequisites
- AWS Account (Free Tier works)
- SageMaker Studio domain set up
- IAM role with S3, Lambda, CloudWatch permissions

### Steps

**1. Set up SageMaker Studio**
```
AWS Console ‚Üí SageMaker ‚Üí Domains ‚Üí Create Domain (Quick Setup)
```

**2. Configure IAM Role**
```
IAM ‚Üí Roles ‚Üí AmazonSageMaker-ExecutionRole ‚Üí Attach Policies:
- AmazonS3FullAccess
- AWSLambda_FullAccess  
- CloudWatchFullAccess
```

**3. Update Trust Policy**
```json
{
  "Version": "2012-10-17",
  "Statement": [{
    "Effect": "Allow",
    "Principal": {
      "Service": ["lambda.amazonaws.com", "sagemaker.amazonaws.com"]
    },
    "Action": "sts:AssumeRole"
  }]
}
```

**4. Upload and Run Notebook**
```
SageMaker Studio ‚Üí JupyterLab ‚Üí Upload MLOps-Sagemaker-Pipeline.ipynb ‚Üí Run All Cells
```

**5. Monitor Pipeline**
```
SageMaker ‚Üí Pipelines ‚Üí FraudDetectXGBPipeline ‚Üí View Execution
```

---

## üí∞ Cost Awareness

| Service | Free Tier | Beyond Free Tier |
|---------|-----------|-----------------|
| SageMaker | 250 hrs/month (ml.t2.medium) | ~$0.05/hr |
| Amazon S3 | 5 GB storage | ~$0.023/GB/month |
| AWS Lambda | 1M requests/month | $0.20/1M requests |
| API Gateway | 1M calls/month | $3.50/1M requests |

**‚úÖ Cost Cleanup Completed:**
- Endpoint deleted after testing
- Lambda function deleted
- Notebook instances stopped
- SageMaker domain deleted
- Only S3 storage retained

---

## üéØ Key Learning Outcomes

‚úÖ Built a **fully automated ML pipeline** using SageMaker Pipelines  
‚úÖ Implemented **conditional deployment** (model only deploys if AUC ‚â• 0.7)  
‚úÖ Used **SageMaker Clarify** for bias detection and SHAP explainability  
‚úÖ Applied **AWS Lambda** for serverless model deployment  
‚úÖ Implemented **Model Registry** for versioning and governance  
‚úÖ Hands-on experience with **IAM roles, S3, CloudWatch**  
‚úÖ Understanding of **MLOps best practices** in production environments  

---

## üîÆ Future Improvements

- [ ] Add **Model Drift Monitoring** using SageMaker Model Monitor
- [ ] Implement **CI/CD pipeline** using GitHub Actions + CodePipeline
- [ ] Add **SageMaker Model Registry** approval workflow
- [ ] Set up **automated retraining** when drift is detected
- [ ] Add **API Gateway** for external access to the endpoint
- [ ] Implement **A/B testing** between model versions

---

## üë©‚Äçüíª Author

**Kritika Aggarwal**  
AI/ML Engineer  
üìß kritikaaggarwal2227@gmail.com  
üîó [LinkedIn](https://linkedin.com/in/kritika-aggarwal-734997249/)  
üíª [GitHub](https://github.com/KritikaK21)

---

> ‚≠ê **Note:** All code is executed inside Amazon SageMaker Studio ‚Äî not locally. The notebook uploads scripts to S3 which are then used by SageMaker processing and training jobs.
